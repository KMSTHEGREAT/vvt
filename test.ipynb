{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "from pickle import load, dump\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_encodings.pkl\", \"rb\") as f:\n",
    "  image_encodings = load(f)\n",
    "\n",
    "with open(\"train_captions.pkl\", \"rb\") as f:\n",
    "  train_captions = load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = dict()\n",
    "captions = train_captions\n",
    "image_features = image_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize the captions\n",
    "input_ids = transformers.tokenization_utils.BatchEncoding(captions)\n",
    "# Create the training data as a list of tuples, each containing an image feature vector and its corresponding caption\n",
    "train_data = ([image_features[i], input_ids[i]] for i in range(len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load the GPT-2 model\n",
    "model = transformers.TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Define the loss function\n",
    "cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Fine-tune the model on your image-caption pairs\n",
    "for epoch in range(10):\n",
    "    for i, (image_features, captions) in enumerate(train_data):\n",
    "        # Encode the prompt with the GPT-2 tokenizer\n",
    "        prompt = \"Image features: \" + image_features\n",
    "        input_ids = tokenizer.encode(captions, return_tensors='tf').to('cuda')\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate text using the GPT-2 model\n",
    "            logits = model(input_ids)\n",
    "            loss = cross_entropy(captions, logits[0, :-1, :])\n",
    "\n",
    "        # Backpropagate the loss and update the weights\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, i+1, len(train_data), loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"gpt2_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
